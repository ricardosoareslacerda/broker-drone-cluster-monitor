version: '3.8'
services:
    kafka:
        image: confluentinc/cp-kafka:5.5.0
        environment:
            KAFKA_BROKER_ID: 1
            KAFKA_ZOOKEEPER_CONNECT: "zookeeper1:2181 zookeeper2:2181 zookeeper3:2181"
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092, PLAINTEXT_HOST://kafka:29092
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT, PLAINTEXT_HOST:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
        volumes:
            #- "/var/run/docker.sock:/var/run/docker.sock"
            - "kafka-data:/var/lib/kafka/data"
            - "kafka-data-logs:/tmp/kafka-logs"
        hostname: kafka
        container_name: kafka
        ports:
            - "29092:29092"
            - "9092:9092"
        networks:
            - broker-net
        restart: always
        depends_on:
            - zookeeper1
        deploy:
            replicas: 1
            placement:
                constraints: [node.role == manager]
                max_replicas_per_node: 1
            restart_policy:
                condition: on-failure
                max_attempts: 1

# Networks to be created to facilitate communication between containers
networks:
    broker-net:
        name: broker-net
        external: true